{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMaQklBSBo1_"
      },
      "source": [
        "필요한 패키지 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoBYTbqFBhvO",
        "outputId": "945b628e-4ff4-4105-9f52-6b08930ccd1d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 10.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.0-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 19.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfkiNSUxC_dN",
        "outputId": "12a5df42-354c-409c-8db6-04b0c64632f4"
      },
      "source": [
        "import torch\n",
        "import numpy as np \n",
        "from tqdm import tqdm # 진행도 표시해주는 함수 \n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer # 자동으로 Pretrained 모델과 토크나이저를 불러와주는 함수 \n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model_name = \"klue/roberta-large\"\n",
        "\n",
        "# 모델과 토크나이저를 전역 변수로 선언 \n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model = model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVTjjaUXEKCe"
      },
      "source": [
        "데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRj00oXZED9-"
      },
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "df = pd.read_csv('dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "fmcBKVkDFIci",
        "outputId": "d82a8ffd-05b9-42e3-e03d-70d64ad6ff47"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>saying</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>에머슨</td>\n",
              "      <td>인생은 하나의 실험이다. 실험이 많아질수록 당신은 더 좋은 사람이 된다.</td>\n",
              "      <td>['인생', '경험']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>파스칼</td>\n",
              "      <td>인생은 우주의 영광이요, 또한 우주의 모욕이다.</td>\n",
              "      <td>['인생']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W. NL. 영안</td>\n",
              "      <td>인생은 반복된 생활이다. 좋은 일을 반복하면 좋은 인생을, 나쁜 일을 반복하면 불행...</td>\n",
              "      <td>['인생', '생활', '반복', '습관']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>파스칼</td>\n",
              "      <td>인생의 최고 불행은 인간이면서 인간을 모르는 것이다.</td>\n",
              "      <td>['인생', '불행', '인간']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>헉슬리</td>\n",
              "      <td>인생의 위대한 목표는 지식이 아니라 행동이다.</td>\n",
              "      <td>['인생', '지식', '행동']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13254</th>\n",
              "      <td>조지 버나드 쇼</td>\n",
              "      <td>황금률은 없다는 것이 황금률이다.</td>\n",
              "      <td>['황금률']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13255</th>\n",
              "      <td>『성경』</td>\n",
              "      <td>악에게 지지 말고, 선으로 악을 이기십시오.</td>\n",
              "      <td>['악(evil)', '선(good)']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13256</th>\n",
              "      <td>영국 속담</td>\n",
              "      <td>죽은 후에는 사는 자가 아니면 산 사람이라고는 할 수 없다.</td>\n",
              "      <td>['죽음', '삶']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13257</th>\n",
              "      <td>A. 쇼펜하워</td>\n",
              "      <td>여성적인 성격의 기본적인 결함은 정의감이 없다는 것이다.</td>\n",
              "      <td>['여성', '정의']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13258</th>\n",
              "      <td>L. 비트겐슈타인</td>\n",
              "      <td>당신이 누구의 사랑을 받고 있다면 어떠한 희생을 치른다 해도 당신은 그 사랑에 해당...</td>\n",
              "      <td>['사랑', '희생']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13259 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         speaker  ...                categories\n",
              "0            에머슨  ...              ['인생', '경험']\n",
              "1            파스칼  ...                    ['인생']\n",
              "2      W. NL. 영안  ...  ['인생', '생활', '반복', '습관']\n",
              "3            파스칼  ...        ['인생', '불행', '인간']\n",
              "4            헉슬리  ...        ['인생', '지식', '행동']\n",
              "...          ...  ...                       ...\n",
              "13254   조지 버나드 쇼  ...                   ['황금률']\n",
              "13255       『성경』  ...    ['악(evil)', '선(good)']\n",
              "13256      영국 속담  ...               ['죽음', '삶']\n",
              "13257    A. 쇼펜하워  ...              ['여성', '정의']\n",
              "13258  L. 비트겐슈타인  ...              ['사랑', '희생']\n",
              "\n",
              "[13259 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4T_rjrrFJd6"
      },
      "source": [
        "class Data:\n",
        "    def __init__(self, id_,speaker,saying, tags):\n",
        "        self.id = id_\n",
        "        self.speaker = speaker\n",
        "        self.saying = saying\n",
        "        self.tags = tags\n",
        "\n",
        "datalist = []\n",
        "\n",
        "for item in df.itertuples():\n",
        "    data = Data(item.Index, item.speaker, item.saying, ast.literal_eval(item.categories))\n",
        "    datalist.append(data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFwQjWf-F4ld",
        "outputId": "83a890d2-aaa9-4ee7-b7ab-6182b29f64da"
      },
      "source": [
        "print(\"id:\", datalist[0].id)\n",
        "print(\"speaker:\",datalist[0].speaker)\n",
        "print(\"saying:\",datalist[0].saying )\n",
        "print(\"tags:\", datalist[0].tags)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 0\n",
            "speaker: 에머슨\n",
            "saying: 인생은 하나의 실험이다. 실험이 많아질수록 당신은 더 좋은 사람이 된다.\n",
            "tags: ['인생', '경험']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75FWHpjfF52Z",
        "outputId": "e774cc28-1d41-43f4-f88d-dd83fc823972"
      },
      "source": [
        "saying = \"인생은 하나의 실험이다. 실험이 많아질수록 당신은 더 좋은 사람이 된다.\"\n",
        "tokenized_input = tokenizer(saying, return_tensors=\"pt\")\n",
        "print(tokenized_input)\n",
        "# 모델에 Dict형식으로 인풋이 들어감.\n",
        "'''\n",
        "{\n",
        "  'input_ids': tokenized된 문장의 텐서\n",
        "  'token_type_ids': 무시해도 됨.\n",
        "  'attention_mask': 이거도 무시해도 됨.\n",
        "}\n",
        "''' \n",
        "for key,val in tokenized_input.items():\n",
        "    tokenized_input[key] = val.to(device) # gpu 있으면 gpu에 올리기. 없으면 그냥 cpu에"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    0,  4545,  2073,  3657,  2079,  5270, 28674,    18,  5270,  2052,\n",
            "          1039,  2227,  2431,  4556,  3994,  2073,   831,  1560,  2073,  3611,\n",
            "          2052,  3622,    18,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mueXjE8NIjDe",
        "outputId": "4dfaee2c-77aa-45e1-a662-1323894c1ad2"
      },
      "source": [
        "outputs = model(**tokenized_input)\n",
        "outputs"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[ 0.0821,  0.0707, -0.3700,  ..., -0.1926, -0.0062,  0.5077],\n",
              "                                                        [ 0.4245, -0.4755, -0.0418,  ..., -0.5073,  0.4965,  0.3767],\n",
              "                                                        [-0.3929,  0.4948,  0.5466,  ..., -0.0375, -0.0730,  0.3291],\n",
              "                                                        ...,\n",
              "                                                        [-0.0530, -0.1398,  0.0446,  ..., -0.0051, -0.3265,  0.5177],\n",
              "                                                        [ 0.1109, -0.0977, -0.3218,  ..., -0.1198,  0.0012,  0.6569],\n",
              "                                                        [ 0.1008,  0.0752, -0.3701,  ..., -0.1857, -0.0015,  0.5165]]],\n",
              "                                                      device='cuda:0', grad_fn=<NativeLayerNormBackward>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[ 0.3049,  0.0287,  0.0650,  ...,  0.0082,  0.1230, -0.2727]],\n",
              "                                                      device='cuda:0', grad_fn=<TanhBackward>))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWmj_6XYKOKg",
        "outputId": "da2514fc-50a5-48da-a4a0-8dfdb2a9855b"
      },
      "source": [
        "#우리가 필요한 건 outputs의 'pooler_output' <- 이게 입력으로 넣은 문장을 대표하는 벡터임. \n",
        "print(outputs.pooler_output)\n",
        "print(outputs.pooler_output.size())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3049,  0.0287,  0.0650,  ...,  0.0082,  0.1230, -0.2727]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward>)\n",
            "torch.Size([1, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk---pEfKZIM",
        "outputId": "2d9cd46c-5e14-4d26-c0dc-571c3be3ab49"
      },
      "source": [
        "# 텐서를 넘파이 벡터로 바꾸기. 만약 node js에서 벡터 연산을 하려면 관련 라이브러리를 찾아봐야 할듯. \n",
        "vector = outputs.pooler_output.detach().squeeze().cpu().numpy()\n",
        "print(type(vector))\n",
        "print(vector)\n",
        "print(vector.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[ 0.304885    0.02867789  0.06504972 ...  0.00815088  0.12302867\n",
            " -0.27273422]\n",
            "(1024,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11ohY33CLMm0"
      },
      "source": [
        "위의 과정을 하나의 함수로 요약"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmS5umuDKvxT"
      },
      "source": [
        "def generate_vector(saying: str) -> np.ndarray:\n",
        "    tokenized_input = tokenizer(saying, return_tensors=\"pt\")\n",
        "    for key,val in tokenized_input.items(): # gpu 있으면 gpu에 올리기\n",
        "        tokenized_input[key] = val.to(device)\n",
        "    outputs = model(**tokenized_input)\n",
        "    vector = outputs.pooler_output.detach().squeeze().cpu().numpy()\n",
        "    return vector"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VNyRqQWRLkVc",
        "outputId": "21881944-594a-4ba4-e72c-dfb3a571c798"
      },
      "source": [
        "datalist[1000].saying"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'모든 거짓 중에서 으뜸가는 가장 나쁜 것은 자기자신을 속이는 일이다.'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X47412iYLvIE",
        "outputId": "72a9a2ee-7f0b-49bd-9045-80cf22560993"
      },
      "source": [
        "vector = generate_vector(\"모든 거짓 중에서 으뜸가는 가장 나쁜 것은 자기자신을 속이는 일이다.\")\n",
        "print(vector)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.27819386  0.04261396 -0.00635708 ... -0.14844678  0.07506038\n",
            " -0.40162823]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYj45RNFMNA9"
      },
      "source": [
        "모든 명언에 대해 벡터 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibJ8_Vh-MAgL",
        "outputId": "dc34a20c-8579-4fd5-97d9-834f4bc014b7"
      },
      "source": [
        "vectors = []\n",
        "\n",
        "for data in tqdm(datalist):\n",
        "    saying = data.saying\n",
        "    vector = generate_vector(saying)\n",
        "    vectors.append(vector)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13259/13259 [09:47<00:00, 22.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQVaRWphMtkF",
        "outputId": "894d8321-0d5e-4db7-fcbe-91fa22b021a4"
      },
      "source": [
        "len(vectors)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13259"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivETAcNsMwIV"
      },
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a,b): # 코사인 유사도 계싼 함수\n",
        "    return dot(a, b)/(norm(a)*norm(b)) "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoqKkInkResp",
        "outputId": "ae8af6eb-cafa-4658-e733-f00b7e0e60fa"
      },
      "source": [
        "cos_sim(vectors[0],vectors[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9727473"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAiLd57JRiCF"
      },
      "source": [
        "def top5(target_id):\n",
        "    target_vector = vectors[target_id]\n",
        "    cos_sims = []\n",
        "    for i,vector in enumerate(vectors):\n",
        "        cos_sims.append((i,cos_sim(target_vector,vector)))\n",
        "    cos_sims.sort(key=lambda x:x[1], reverse=True)\n",
        "    \n",
        "    res = []\n",
        "    for item in cos_sims:\n",
        "        if item[0]!=target_id: res.append(item)\n",
        "        if len(res)==5: break\n",
        "        \n",
        "    print(\"target:\",datalist[target_id].saying)\n",
        "    \n",
        "    print(\"candidates:\")\n",
        "    for i, sim in res:\n",
        "        print(i,datalist[i].saying,sim)\n",
        "    return res"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ngfVaXMgRm7Z",
        "outputId": "5efdda39-cfd1-4f78-ee02-cea7fe2a3c53"
      },
      "source": [
        "target_id = 1000\n",
        "datalist[target_id].saying"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'모든 거짓 중에서 으뜸가는 가장 나쁜 것은 자기자신을 속이는 일이다.'"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En_ZCLp0Rwgy",
        "outputId": "bf0bd6c5-3ead-4ee1-cc8a-f775dfb6588d"
      },
      "source": [
        "res = top5(target_id)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target: 모든 거짓 중에서 으뜸가는 가장 나쁜 것은 자기자신을 속이는 일이다.\n",
            "candidates:\n",
            "9924 결점 중에서 가장 큰 결점은 그것을 깨닫지 못하는 것이다. 0.99804085\n",
            "3831 학문의 최대의 적은 자기 마음속에 있는 유혹이다. 0.99797887\n",
            "8599 얌전한 체하는 것은 허욕의 일종이요, 모든 허욕 중에 가장 나쁜 것이다. 0.99793625\n",
            "10555 어리석은 짓을 삼가는 것이 지혜의 입문이다. 0.9977756\n",
            "2583 속이는 말로 재물을 모으는 것은 죽음을 구하는 것이다. 0.99768245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADLi5l2pRzMy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}